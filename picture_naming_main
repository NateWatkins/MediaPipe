import os
import glob
import cv2
import numpy as np
import pandas as pd
from types import SimpleNamespace
from natsort import natsorted
import mediapipe as mp
from contextlib import contextmanager

mp_holistic = mp.solutions.holistic
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# ============================ User-tunable globals ============================
ANNOTATE_EVERY = 1    
RESIZE_MAX_WIDTH = None   # e.g., 960; set None to keep original resolution

OUTPUT_ROOT = "../output_subjects"
# ---- Paths ----

NORMALIZE_TO_NOSE = True


IMAGE_EXTS = (".jpg", ".JPG", ".png", ".PNG")
VIDEO_EXTS = (".mov", ".MOV",".mp4",".m4v")

#Frame Folder Controls 
FRAME_LIMIT = 50      
FRAME_STRIDE = 1        
### This is the video controls
FRAME_LIMIT_VIDEO = 270  
FRAME_STRIDE_VIDEO = 1    


detectionConfidence = .5
trackingConfidence = .5




def get_frame_paths(frames_dir):
    paths = []
    for ext in IMAGE_EXTS:
        paths.extend(glob.glob(os.path.join(frames_dir, f"*{ext}")))
    return natsorted(paths)

def validate_inputs():
    video_ok  = bool(VIDEO_PATH and os.path.isfile(VIDEO_PATH) and VIDEO_PATH.endswith(VIDEO_EXTS))
    frames_ok = bool(FRAMES_DIR and os.path.isdir(FRAMES_DIR))
    if not video_ok:
        print(f"⚠ VIDEO_PATH not usable (skipping): {VIDEO_PATH}")
    if not frames_ok:
        print(f"⚠ FRAMES_DIR not usable (skipping): {FRAMES_DIR}")
    if video_ok or frames_ok:
        print("✓ At least one valid input found.")
    else:
        print("✗ No valid inputs found.")
    return video_ok, frames_ok

# ============================ Constants ============================
pose_landmark_names = {
    0: "nose", 1: "left_eye_inner", 2: "left_eye", 3: "left_eye_outer",
    4: "right_eye_inner", 5: "right_eye", 6: "right_eye_outer", 7: "left_ear",
    8: "right_ear", 9: "mouth_left", 10: "mouth_right", 11: "left_shoulder",
    12: "right_shoulder", 13: "left_elbow", 14: "right_elbow", 15: "left_wrist",
    16: "right_wrist", 17: "left_pinky", 18: "right_pinky", 19: "left_index",
    20: "right_index", 21: "left_thumb", 22: "right_thumb", 23: "left_hip",
    24: "right_hip", 25: "left_knee", 26: "right_knee", 27: "left_ankle",
    28: "right_ankle", 29: "left_heel", 30: "right_heel",
    31: "left_foot_index", 32: "right_foot_index"
}

hand_landmark_names = {
    0: "wrist", 1: "thumb_cmc", 2: "thumb_mcp", 3: "thumb_ip", 4: "thumb_tip",
    5: "index_mcp", 6: "index_pip", 7: "index_dip", 8: "index_tip",
    9: "middle_mcp", 10: "middle_pip", 11: "middle_dip", 12: "middle_tip",
    13: "ring_mcp", 14: "ring_pip", 15: "ring_dip", 16: "ring_tip",
    17: "pinky_mcp", 18: "pinky_pip", 19: "pinky_dip", 20: "pinky_tip"
}

def create_folders():
    os.makedirs("output_data", exist_ok=True)
from scipy.signal import butter, filtfilt

def _butterworth_lowpass(signal, cutoff_hz=4, fs=30.0, order=4):
    nyquist = 0.5 * fs
    wn = cutoff_hz / nyquist
    wn = min(max(wn, 1e-6), 0.999999)  # clamp to (0,1)
    b, a = butter(order, wn, btype="low", analog=False)
    return filtfilt(b, a, signal)


def _interp_short_nans(series, limit=5):
    # interpolate short NaN runs; leave long gaps as NaN
    return series

def _build_allowlist_cols(df, bases):
    # expand joint base names -> existing x/y/z columns in df
    cols = []
    for base in bases:
        for axis in ("x","y"):
            c = f"{base}_{axis}"
            if c in df.columns:
                cols.append(c)
    return cols

def save_csv_files(face_data, body_data, hand_data, fps=30.0, cutoff_hz=4.0, order=2, folder_type=None):
    base_folder = os.path.join(OUTPUT_ROOT, clip_name)   # <- OUTPUT_ROOT already scoped by use_output_root
    os.makedirs(base_folder, exist_ok=True)

    # ---- to DataFrames ----
    face_df = pd.DataFrame(face_data)
    body_df = pd.DataFrame(body_data)
    hand_df = pd.DataFrame(hand_data)

    # If we’re in a “filtered” run, normalize in-place before saving
    if NORMALIZE_TO_NOSE:
        face_df, body_df, hand_df = _normalize_to_nose(face_df, body_df, hand_df)

    # ---- write once to the scoped output dir ----
    face_df.to_csv(os.path.join(base_folder, f"{subject_id}_{folder_type}_face.csv"), index=False, float_format="%.10f")
    body_df.to_csv(os.path.join(base_folder, f"{subject_id}_{folder_type}_body.csv"), index=False, float_format="%.10f")
    hand_df.to_csv(os.path.join(base_folder, f"{subject_id}_{folder_type}_hand.csv"), index=False, float_format="%.10f")

    if folder_type == "Frames":
        print(f"✓ Saved data in {base_folder}/")
    elif folder_type == "Video":
        print(f"✓ Saved data in {base_folder}/")

    return face_df, body_df, hand_df, None, None, None


def _normalize_to_nose(face_df, body_df, hand_df):
    # Only if nose exists
    if 'nose_x' not in body_df.columns or 'nose_y' not in body_df.columns:
        return face_df, body_df, hand_df

    ax = body_df['nose_x']  # anchor series per row
    ay = body_df['nose_y']

    def _shift_df(df):
        xcols = [c for c in df.columns if c.endswith('_x')]
        ycols = [c for c in df.columns if c.endswith('_y')]
        # Vectorized row-wise subtraction; NaNs in ax/ay will propagate (acceptable)
        df[xcols] = df[xcols].sub(ax, axis=0)
        df[ycols] = df[ycols].sub(ay, axis=0)
        return df

    face_df = _shift_df(face_df)
    body_df = _shift_df(body_df)
    hand_df = _shift_df(hand_df)
    return face_df, body_df, hand_df

def extract_face_data(results, frame_num):
    face = {'frame': frame_num}
    if results and results.face_landmarks:
        for i, lm in enumerate(results.face_landmarks.landmark):
            face[f'face_{i}_x'] = lm.x
            face[f'face_{i}_y'] = lm.y
            #face[f'face_{i}_z'] = lm.z
    else:
        for i in range(468):
            face[f'face_{i}_x'] = np.nan
            face[f'face_{i}_y'] = np.nan
            #face[f'face_{i}_z'] = np.nan
    return face

def extract_body_data(results, frame_num):
    body = {'frame': frame_num}
    if results and results.pose_landmarks:
        for i, lm in enumerate(results.pose_landmarks.landmark):
            jn = pose_landmark_names[i]
            body[f'{jn}_x'] = lm.x
            body[f'{jn}_y'] = lm.y
            #body[f'{jn}_z'] = lm.z
            body[f'{jn}_visibility'] = lm.visibility
    else:
        for i in range(33):
            jn = pose_landmark_names[i]
            body[f'{jn}_x'] = np.nan
            body[f'{jn}_y'] = np.nan
            #body[f'{jn}_z'] = np.nan
            body[f'{jn}_visibility'] = np.nan
            #body[f'{jn}_pose_detection_confidence'] = 0.0
    return body

def extract_hand_data(results, frame_num):
    hand = {
        'frame': frame_num,
    }
    if results and results.left_hand_landmarks:
        for i, lm in enumerate(results.left_hand_landmarks.landmark):
            jn = hand_landmark_names[i]
            hand[f'left_{jn}_x'] = lm.x
            hand[f'left_{jn}_y'] = lm.y
            #hand[f'left_{jn}_z'] = lm.z
    else:
        for i in range(21):
            jn = hand_landmark_names[i]
            hand[f'left_{jn}_x'] = np.nan
            hand[f'left_{jn}_y'] = np.nan
            #hand[f'left_{jn}_z'] = np.nan
    if results and results.right_hand_landmarks:
        for i, lm in enumerate(results.right_hand_landmarks.landmark):
            jn = hand_landmark_names[i]
            hand[f'right_{jn}_x'] = lm.x
            hand[f'right_{jn}_y'] = lm.y
            #hand[f'right_{jn}_z'] = lm.z
    else:
        for i in range(21):
            jn = hand_landmark_names[i]
            hand[f'right_{jn}_x'] = np.nan
            hand[f'right_{jn}_y'] = np.nan
            #hand[f'right_{jn}_z'] = np.nan
    return hand

def _maybe_resize(img_bgr):
    if RESIZE_MAX_WIDTH is None:
        return img_bgr
    h, w = img_bgr.shape[:2]
    if w <= RESIZE_MAX_WIDTH:
        return img_bgr
    scale = RESIZE_MAX_WIDTH / float(w)
    new_w, new_h = int(w * scale), int(h * scale)
    return cv2.resize(img_bgr, (new_w, new_h), interpolation=cv2.INTER_AREA)

def process_frames_folder(frames_dir=None):
    if not frames_dir or not os.path.isdir(frames_dir):
        print(f"Invalid frames_dir: {frames_dir}")
        return
    print(f"Processing frames in: {frames_dir}")
    frame_paths = get_frame_paths(frames_dir)
    if not frame_paths:
        print("No images found."); return
    total_frames = len(frame_paths)
    print(f"Using {total_frames} frames ")
    holistic = mp_holistic.Holistic(
        static_image_mode=False,
        model_complexity=2,
        smooth_landmarks=True,
        min_detection_confidence=detectionConfidence,
        min_tracking_confidence=trackingConfidence,
        refine_face_landmarks=True,
        enable_segmentation=True,  ##Get the segmentation mask of the person vs background pickle file. docs
        smooth_segmentation=True,
    )

    face_data, body_data, hand_data = [], [], []
    for frame_num, fpath in enumerate(frame_paths):
        img_bgr = cv2.imread(fpath)
        if img_bgr is None:
            empty = SimpleNamespace(face_landmarks=None, pose_landmarks=None,
                                    left_hand_landmarks=None, right_hand_landmarks=None)
            face_data.append(extract_face_data(empty, frame_num))
            body_data.append(extract_body_data(empty, frame_num))
            hand_data.append(extract_hand_data(empty, frame_num))
            continue
        img_bgr_resized = _maybe_resize(img_bgr)
        rgb = cv2.cvtColor(img_bgr_resized, cv2.COLOR_BGR2RGB)
        results = holistic.process(rgb)
        face_data.append(extract_face_data(results, frame_num))
        body_data.append(extract_body_data(results, frame_num))
        hand_data.append(extract_hand_data(results, frame_num))

        if (frame_num + 1) % 100 == 0:
            print(f"Progress: {frame_num + 1}/{total_frames}")
        if frame_num >= FRAME_LIMIT:
            print("Frame limit reached.")
            break
        
    holistic.close()
    save_csv_files(face_data, body_data, hand_data, folder_type="Frames")

    print(f"✓ Completed folder: {clip_name}")

def process_video(video_path=None):
    print(f"Processing video: {os.path.basename(video_path)}")
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Cannot open video."); return None
    total_frames_raw = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or -1
    holistic = mp_holistic.Holistic(
        static_image_mode=False,
        model_complexity=2,
        smooth_landmarks=True,
        min_detection_confidence=detectionConfidence,
        min_tracking_confidence=trackingConfidence,
        refine_face_landmarks=True,
        enable_segmentation=True,
        smooth_segmentation=True,
    )
    face_data, body_data, hand_data = [], [], []
    frame_num = 0 
    processed = 0

    print(f"Video testing controls → limit={FRAME_LIMIT_VIDEO}, stride={FRAME_STRIDE_VIDEO}")
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        if isinstance(FRAME_STRIDE_VIDEO, int) and FRAME_STRIDE_VIDEO > 1:
            if (frame_num % FRAME_STRIDE_VIDEO) != 0:
                frame_num += 1
                continue
        frame_resized = _maybe_resize(frame)
        rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
        results = holistic.process(rgb)

        face_data.append(extract_face_data(results, frame_num))
        body_data.append(extract_body_data(results, frame_num))
        hand_data.append(extract_hand_data(results, frame_num))

        processed += 1
        frame_num += 1
        
        if processed % 100 == 0:
            if total_frames_raw > 0:
                print(f"Processed {processed} frames (raw index ~{frame_num}/{total_frames_raw})")
            else:
                print(f"Processed {processed} frames")
        if processed >= FRAME_LIMIT:
            print("Frame limit reached.")
            break
        
    cap.release()
    holistic.close()
    save_csv_files(face_data, body_data, hand_data, folder_type="Video")
    print(f"✓ Completed video: {clip_name} ")
    return True


def ensure_mp_dirs(root, sub_id):
    unf = os.path.join(root, sub_id, "Unfiltered_MP_Data")
    fil = os.path.join(root, sub_id, "Filtered_MP_Data")
    os.makedirs(unf, exist_ok=True)
    os.makedirs(fil, exist_ok=True)
    return unf, fil

@contextmanager
def use_output_root(path):
    global OUTPUT_ROOT
    _old = OUTPUT_ROOT
    OUTPUT_ROOT = path
    try:
        yield
    finally:
        OUTPUT_ROOT = _old



def main():
    print("MediaPipe Holistic Extraction (Batch)")
    print("====================================")
    global BASE_OUT
    done_file = "../config/done.csv"
    done = set(open(done_file).read().split()) if os.path.exists(done_file) else set()
    global OUTPUT_ROOT
    BASE_OUT = OUTPUT_ROOT  # remember original root
    

    #Big if/for loop here for filtered and non filtered.


    if not os.path.exists("../config/participants.csv"):
        print("No participants.csv file found.")
        return

    with open("../config/participants.csv") as f:
        lines = [l.strip() for l in f if l.strip()]

 

    for line in lines:
        sub_id, video_path, frames_dir = line.split(",")
        tag_frames = f"{line}#frames"
        tag_video  = f"{line}#video"
        global clip_name
        global subject_id
        subject_id = sub_id
        UNFILT_DIR, FILT_DIR = ensure_mp_dirs(BASE_OUT, sub_id)
        target_dir = FILT_DIR if NORMALIZE_TO_NOSE else UNFILT_DIR
        





        global VIDEO_PATH, FRAMES_DIR
        VIDEO_PATH, FRAMES_DIR = video_path, frames_dir

        print(f"\n=== Processing {sub_id} ===")
        video_ok, frames_ok = validate_inputs()

        if frames_ok and tag_frames not in done:
            with use_output_root(target_dir):
                clip_name = "Frames"
                process_frames_folder(frames_dir)
            with open(done_file, "a") as df: df.write(tag_frames + "\n")

        if video_ok and tag_video not in done:
            with use_output_root(target_dir):
                clip_name = "RGB"
                process_video(video_path)
            with open(done_file, "a") as df: df.write(tag_video + "\n")
        OUTPUT_ROOT = BASE_OUT

    print("\nAll participants processed ✓")



if __name__ == "__main__":
    main()


