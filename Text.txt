We want to find the most volatile moment in the video using joint velocity information and then be able to pull the frame where that happens. 
We will probably need a separate function or maybe another file.




We also want to capture the moment of greatest change in velocity for the joints. This will later be combined with other factors for a fuller analysis.
First step is just to get everything running on RGB frames, cut it down to the first 200 frames to test. Then try out different model parameters, track the differences, and report what changes.



Outputs will include CSV files, and weâ€™ll make time series plots to see whether the curves show meaningful changes.

Where we are right now:
Segmentation masks are being saved into the right folder.
Graphs and charts are working for both position and velocity.
Filtered and unfiltered data can be compared with shadows.
CSV outputs are working.
Already have a preliminary README, but this is a new set of notes to capture the current progress.


Created the new readME.md 
- Incldues a quick start quide
- Shows main functions in depth

Added the unfiltered data lines to both graphs




Explain terms that need explanation. This document should give them a leg up on understand the material
give documentation. HSould be intructional for the person who follows. What you have learned.

What parameters were used for everything 

...used these parameters and where you can change them too


Dependencies before quick start....Cna be installed -> 

Comprehensive 

what is the output. what folder structure does this expect 


one graph index finger velocity and position. One video maybe



first 9 seconds 



next steps is finding what informaiton hsould be outputed for each participant and createa. oflder system. Goal for the end of the month is to have all the output